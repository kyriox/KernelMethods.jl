{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un-comment if you want to install KernelMethods with KMS Module and RDatasets respectively.*\n",
    "#using Pkg\n",
    "#pkg\"add https://github.com/kyriox/KernelMethods.jl\"\n",
    "#pkg\"add RDatasets\"\n",
    "pkg\"add ProgressMeter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/job/.julia/compiled/v1.1/KernelMethods/lt5mb.ji for KernelMethods [d79e8f30-5872-11e9-0dab-2d1842b87615]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package KernelMethods does not have PyCall in its dependencies:\n",
      "│ - If you have KernelMethods checked out for development and have\n",
      "│   added PyCall as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with KernelMethods\n",
      "└ Loading PyCall into KernelMethods from project dependency, future warnings for KernelMethods are suppressed.\n",
      "┌ Info: Recompiling stale cache file /Users/job/.julia/compiled/v1.1/RDatasets/JyIbx.ji for RDatasets [ce6b1742-4840-55fa-b093-852dadbb1d8b]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using KernelMethods: KMS, predict, recall, LabelEncoder\n",
    "using RDatasets\n",
    "using Random\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Model Selection for Classification tasks\n",
    "\n",
    "Our method Kernel Model Selection(KMS) integrates algorithms inspired by prototypes selection and generation, kernel functions and k-Nearest Neighbors and Naive Bayes classifiers. This integration results in the KMS classification pipeline.  We perform a model selection is using random search on the space formed with the different algorithms; and, the performance is obtained using a k-fold cross-validation approach. Furthermore, the computational cost of performing the random search is exploited with the creation of an ensemble; this ensemble outperforms the base classifiers. Next table shows default parameters for Random Search process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "|        **Name**        |                **Value**                 |\n",
    "|------------------------|------------------------------------------|\n",
    "|Number of prototyes $k$ | $$\\{4,8,16,32,64\\}$$ |\n",
    "|Distance function       | $$\\{Angle, Euclidean\\}$$ |\n",
    "|Sampling method         | $$\\{Density,\\mathit{FFT}^*, \\mathit{K-Means}, \\mathit{Random}\\}$$      | \n",
    "|Kernel function         | $$\\{\\mathit{Linear}, \\mathit{Gaussian}, \\mathit{Sigmoid}, \\mathit{Cauchy}\\}$$|\n",
    "|Reference's type        | $$\\{\\mathit{Centers}, \\mathit{Centroids}\\}$$|\n",
    "|Internal classifiers    | $$\\{\\mathit{Naïive Bayes}, k\\mathit{NN}\\}$$|\n",
    "|$k$NN weighting scheme  | $$\\{\\mathit{Distance}, \\mathit{Uniform}\\}$$|\n",
    "|$k$NN distance function | $$\\{\\mathit{Cosine}, \\mathit{Euclidean}\\}$$ \n",
    "|Number of neighbors     | $$\\{1,5,11,21\\}$$|\n",
    "|Sample size             | $$128$$|\n",
    "|Number of folds         | $$3$$ |\n",
    "\n",
    "------\n",
    "\\*Farthest First Traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "As an example, an experiment of 30 runs of KMS is performed, for effects of contrasting the mean an variance for the top KMS and an ensemble of size $t=15$ is reported. \n",
    "Please note that train and test splits are generated randomly and results may vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load de Iris Dataset \n",
    "iris = dataset(\"datasets\", \"iris\"); \n",
    "lencoder=LabelEncoder(iris.Species);\n",
    "#labels must be an array of integer values.\n",
    "labels=[lencoder.imap[x] for x in iris.Species]; \n",
    "#data must be an array of 1D arrays.\n",
    "data=[collect(x) for x  in zip(iris.SepalLength,iris.SepalWidth,iris.PetalLength,iris.PetalWidth)];\n",
    "n=length(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a couple of minutes\n",
    "kms_results,kmse15_results=[],[] # List to store score values for each run\n",
    "for i in 1:30\n",
    "    ind,idx=randperm(n),trunc(Int, 0.7*n) # 70-30 train/validation split\n",
    "    it,iv=ind[1:idx], ind[idx+1:end]\n",
    "    Xt,yt=data[it],labels[it]\n",
    "    Xv,yv=data[iv],labels[iv]\n",
    "    kn=KMS(Xt,yt) # instacing and training KMS\n",
    "    yp=predict(kn,Xv) # predict  validation lables using the top KMS at training phase\n",
    "    yp15=predict(kn,Xv, ensemble_k=15) #predict validation lables using the top 15 KMS \n",
    "    # recording recall score (recall is used as defualt score)\n",
    "    push!(kms_results, recall(yv,yp))\n",
    "    push!(kmse15_results, recall(yv,yp15))  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mean(kms_results), std(kms_results)) = (0.9676119113657814, 0.023034053452944573)\n"
     ]
    }
   ],
   "source": [
    "# Averege and variance for top classifier \n",
    "@show mean(kms_results), std(kms_results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mean(kmse15_results), std(kmse15_results)) = (0.9747210215347469, 0.01979729965163568)\n"
     ]
    }
   ],
   "source": [
    "# Averege and variance for an ensemble of size 15\n",
    "@show mean(kmse15_results), std(kmse15_results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Even though results may vary, the ensemble consistently outperforms top classifier exihibiting higher mean recall and lower deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
