{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un-comment if you want to install KernelMethods with KMS Module and RDatasets respectively.*\n",
    "#using Pkg\n",
    "#pkg\"add https://github.com/kyriox/KernelMethods.jl\"\n",
    "#pkg\"add RDatasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/job/.julia/compiled/v1.1/KernelMethods/lt5mb.ji for KernelMethods [d79e8f30-5872-11e9-0dab-2d1842b87615]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Package KernelMethods does not have PyCall in its dependencies:\n",
      "│ - If you have KernelMethods checked out for development and have\n",
      "│   added PyCall as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with KernelMethods\n",
      "└ Loading PyCall into KernelMethods from project dependency, future warnings for KernelMethods are suppressed.\n"
     ]
    }
   ],
   "source": [
    "using KernelMethods: KMS, predict, recall, LabelEncoder\n",
    "using RDatasets\n",
    "using Random\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Model Selection for Classification tasks\n",
    "\n",
    "Our method Kernel Model Selection(KMS) integrates algorithms inspired by prototypes selection and generation, kernel functions and k-Nearest Neighbors and Naive Bayes classifiers. This integration results in the KMS classification pipeline.  We perform a model selection is using random search on the space formed with the different algorithms; and, the performance is obtained using a k-fold cross-validation approach. Furthermore, the computational cost of performing the random search is exploited with the creation of an ensemble; this ensemble outperforms the base classifiers. Next table shows default parameters for Random Search process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1**\n",
    "\n",
    "------\n",
    "\n",
    "|        **Name**        |                **Value**                 |\n",
    "|------------------------|------------------------------------------|\n",
    "|Number of prototyes $k$ | $$\\{4,8,16,32,64\\}$$ |\n",
    "|Distance function       | $$\\{Angle, Euclidean\\}$$ |\n",
    "|Sampling method         | $$\\{Density,\\mathit{FFT}^*, \\mathit{K-Means}, \\mathit{Random}\\}$$      | \n",
    "|Kernel function         | $$\\{\\mathit{Linear}, \\mathit{Gaussian}, \\mathit{Sigmoid}, \\mathit{Cauchy}\\}$$|\n",
    "|Reference's type        | $$\\{\\mathit{Centers}, \\mathit{Centroids}\\}$$|\n",
    "|Internal classifiers    | $$\\{\\mathit{Naive Bayes}, k\\mathit{NN}\\}$$|\n",
    "|$k$NN weighting scheme  | $$\\{\\mathit{Distance}, \\mathit{Uniform}\\}$$|\n",
    "|$k$NN distance function | $$\\{\\mathit{Cosine}, \\mathit{Euclidean}\\}$$ \n",
    "|Number of neighbors     | $$\\{1,5,11,21\\}$$|\n",
    "|Sample size             | $$128$$|\n",
    "|Number of folds         | $$3$$ |\n",
    "\n",
    "------\n",
    "\\*Farthest First Traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "As an example, an experiment of 30 runs of KMS is performed, for effects of contrasting the mean an variance for the top KMS and an ensemble of size $t=15$ is reported. \n",
    "Please note that train and test splits are generated randomly and results may vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load de Iris Dataset \n",
    "iris = dataset(\"datasets\", \"iris\"); \n",
    "lencoder=LabelEncoder(iris.Species);\n",
    "#labels must be an array of integer values.\n",
    "labels=[lencoder.imap[x] for x in iris.Species]; \n",
    "#data must be an array of 1D arrays.\n",
    "data=[collect(x) for x  in zip(iris.SepalLength,iris.SepalWidth,iris.PetalLength,iris.PetalWidth)];\n",
    "n=length(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"iteration $(i) of $(ni)\" = \"iteration 5 of 30\"\n",
      "\"iteration $(i) of $(ni)\" = \"iteration 10 of 30\"\n",
      "\"iteration $(i) of $(ni)\" = \"iteration 15 of 30\"\n",
      "\"iteration $(i) of $(ni)\" = \"iteration 20 of 30\"\n"
     ]
    }
   ],
   "source": [
    "# This may take a couple of minutes\n",
    "kms_results,kmse15_results=[],[] # List to store score values for each run\n",
    "ni=30\n",
    "for i in 1:ni\n",
    "    ind,idx=randperm(n),trunc(Int, 0.7*n) # 70-30 train/validation split\n",
    "    it,iv=ind[1:idx], ind[idx+1:end]\n",
    "    Xt,yt=data[it],labels[it]\n",
    "    Xv,yv=data[iv],labels[iv]\n",
    "    kn=KMS(Xt,yt) # instacing and training KMS\n",
    "    yp=predict(kn,Xv) # predict  validation lables using the top KMS at training phase\n",
    "    yp15=predict(kn,Xv, ensemble_k=15) #predict validation lables using the top 15 KMS \n",
    "    # recording recall score (recall is used as defualt score)\n",
    "    push!(kms_results, recall(yv,yp))\n",
    "    push!(kmse15_results, recall(yv,yp15))\n",
    "    if i%5+1==1\n",
    "        @show \"iteration $i of $ni\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averege and variance for top classifier \n",
    "@show mean(kms_results), std(kms_results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averege and variance for an ensemble of size 15\n",
    "@show mean(kmse15_results), std(kmse15_results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Even though results may vary, the ensemble consistently outperforms top classifier exihibiting higher mean recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMS function' parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for $\\mathit{KMS}$ are basically the ones describe a Table 1, but, there are a number of aditional parameters, functions are passed as Symbols and some names are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function $\\mathit{KMS}(X,Y;\\mathit{op\\_function},\\mathit{top\\_k},\\mathit{folds},\\mathit{udata},\\mathit{nets},\\mathit{K},\\mathit{distances},\\mathit{distancesk},\\mathit{sample\\_size},\\mathit{kernels},\\mathit{debug})$\n",
    "\n",
    "- Positional arguments:\n",
    "    - X  must be an array of 1D arrays with the training samples \n",
    "    - Y  must an 1D array of size |X|, where each element $y_i \\in Y$ corresponds to the label for each $x_i \\in X$  \n",
    "- Keyword arguments:\n",
    "    - $kernels$ is a list of kernel functions, each element in the list  must be a symbol which can be evaluated as a function. Default value is  \\[*:gaussian*,*:linear*,*:cauchy*,*:sigmoid*\\]. Any custom fucntion may be used.\n",
    "    - $K$, is a list of intergers containing the values for the number of references. By default $K=[4,8,16,32,64]$\n",
    "    - $\\mathit{op\\_function}$ is the fitness function, it must be a symbol which can be evaluate as a function. By default is set to *:recall*, but, it can be any of the ones define in scores; as well as user defined.\n",
    "    - $\\mathit{top\\_k}$ the number of top classifiers to be keep during training phase. By default is set to 15. \n",
    "    - udata, allows to include unlabeled data to be used for the sampling process, it must be an array of 1D arrays; the 1D arrays have to be of the same cardinality that the ones in $X$. Default value is  set to [].\n",
    "    - nets, is the list of sampling algorithms to be used to select the references. The list can include any combination of the symbols *{:fft\\_sampling, :kmeans\\_sampling, :density\\_sampling, :random\\_sampling}*. By default a list with the four symbols is used. \n",
    "    - $\\mathit{distancesk}$ is the list of distances functions to be used for the sampling methods.  Default value is set to \\[*:angle*,*squared_l2_distance*\\], note that any pair metric may be used.\n",
    "    \n",
    "    - $\\mathit{distances}$, is the list of distances which may be used when $k$NN classifier is selected. We set $\\mathit{distances}=$ \\[*:cosine*, *:euclidean*\\] as default value.\n",
    "    - $\\mathit{sample\\_size}$, the number of the configurations to be evaluated by the random search process. Default value is set to 128. If the grid size is lower than $\\mathit{sample\\_size}$, or  $\\mathit{sample\\_size}=-1$ then,  all the grid is evaluated.\n",
    "    - folds, is the number of folds to be performed during the train phase. Default value is 3.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only two sampling strategies FFT and KMeans\n",
    "kna=KMS(data,labels; op_function=:recall,top_k=15,folds=3,udata=[], \n",
    "    nets=[:fft_sampling,:kmeans_sampling], #here\n",
    "    K=[4,8,16,32,64],distances=[:angle,:squared_l2_distance],\n",
    "    distancesk=[:angle,:squared_l2_distance],sample_size=128,\n",
    "    kernels=[:gaussian,:linear,:cauchy,:sigmoid]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(labels,predict(kna,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
